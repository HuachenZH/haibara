{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "In the last section i've seen linear regression. **Linear regression** is used to predict numeric value.  \n",
    "**Classification** is used to seperated data points into different classes of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import absolut_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "It's possible to use tf.keras.utils.get_file to get file from a url, and store it to cache.  \n",
    "Still, i prefer to use local files to avoid api calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "0          6.4         2.8          5.6         2.2\n",
      "1          5.0         2.3          3.3         1.0\n",
      "2          4.9         2.5          4.5         1.7\n",
      " \n",
      "The shape is train is (120, 4)\n"
     ]
    }
   ],
   "source": [
    "train_path = \"data/iris/iris_training.csv\"\n",
    "test_path = \"data/iris/iris_test.csv\"\n",
    "\n",
    "# define some constants to help us later on\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "# read dataset\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "# names: list of column names to use.\n",
    "# header: row number(s) to use as the column names.\n",
    "\n",
    "# pop the species column off\n",
    "train_y = train.pop(\"Species\")\n",
    "test_y = test.pop(\"Species\")\n",
    "\n",
    "print(train.head(3)) # the Species column is now gone.\n",
    "print(' ')\n",
    "print(\"The shape is train is %s\" % str(train.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input function\n",
    "We need to create input function again. This time it will be easier to digest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # convert the inputs to a dataset\n",
    "    dataset = tf.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # shuffle and repeat if you are in training mode\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few explanation of the above code.\n",
    "- `tf.Dataset.from_tensor_slices()` is used to create input pipeline for machine learning models. It creates a `tf.data.Dataset`object.\n",
    "- `dataset.shuffle(1000).repeat()` the `repeat()` method:  \n",
    "`repeat(count=None, name=None)` is used to repeat dataset so each original value is seen count times. While put nothing, the dataset will be repeated indefinitely."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature columns\n",
    "Don't forget feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n",
      " \n",
      "tmp2 is <keras.utils.feature_space.FeatureSpace object at 0x000002347FEC3DC0>\n"
     ]
    }
   ],
   "source": [
    "# Feature columns describe how to use the input\n",
    "my_feature_columns = []\n",
    "for key in train.keys(): # train is pd dataframe. .keys() is used to get column names\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_feature_columns)\n",
    "print(' ')\n",
    "# WARNING:tensorflow:From C:\\Users\\eziod\\AppData\\Local\\Temp\\ipykernel_17516\\269687074.py:5: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
    "# Instructions for updating:\n",
    "# Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
    "\n",
    "tmp = {}\n",
    "tmp['SepalLength'] = \"float\"\n",
    "tmp['SepalWidth'] = \"float\"\n",
    "tmp['PetalLength'] = \"float\"\n",
    "tmp['PetalWidth'] = \"float\"\n",
    "tmp2 = tf.keras.utils.FeatureSpace(tmp) \n",
    "print(\"tmp2 is %s\" % tmp2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few explanations...\n",
    "- `df.keys()` and `df.columns` are nearly the same. While `.columns` can be used to set column labels, `.keys()` is \"read only\".\n",
    "- `tf.feature_column.numeric_column(key=key)` returns an object of type \"<class 'tensorflow.python.feature_column.feature_column_v2.NumericColumn'>\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
